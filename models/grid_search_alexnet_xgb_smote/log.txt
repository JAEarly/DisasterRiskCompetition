             Etas: [0.25, 0.35]
           Gammas: [0, 1]
           Depths: [1, 5, 8]
Min Child Weights: [1, 2]
          Lambdas: [0.5, 1.5]

-- Configuration 1/48 --
eta - 0.25
gamma - 0
depth - 1
c_weight - 1
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6094221198495398
 Best Acc: 0.3280141843971631
 Avg Loss: 1.6094221198495398
  Avg Acc: 0.3280141843971631

-- Configuration 2/48 --
eta - 0.25
gamma - 0
depth - 1
c_weight - 1
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6093820149065754
 Best Acc: 0.16622340425531915
 Avg Loss: 1.6093820149065754
  Avg Acc: 0.16622340425531915

-- Configuration 3/48 --
eta - 0.25
gamma - 0
depth - 1
c_weight - 2
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6094431541067489
 Best Acc: 0.3271276595744681
 Avg Loss: 1.6094431541067489
  Avg Acc: 0.3271276595744681

-- Configuration 4/48 --
eta - 0.25
gamma - 0
depth - 1
c_weight - 2
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6093820149065754
 Best Acc: 0.16622340425531915
 Avg Loss: 1.6093820149065754
  Avg Acc: 0.16622340425531915

-- Configuration 5/48 --
eta - 0.25
gamma - 0
depth - 5
c_weight - 1
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6089909811180534
 Best Acc: 0.20079787234042554
 Avg Loss: 1.6089909811180534
  Avg Acc: 0.20079787234042554

-- Configuration 6/48 --
eta - 0.25
gamma - 0
depth - 5
c_weight - 1
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6089138292991523
 Best Acc: 0.2641843971631206
 Avg Loss: 1.6089138292991523
  Avg Acc: 0.2641843971631206

-- Configuration 7/48 --
eta - 0.25
gamma - 0
depth - 5
c_weight - 2
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.608970767745735
 Best Acc: 0.18927304964539007
 Avg Loss: 1.608970767745735
  Avg Acc: 0.18927304964539007

-- Configuration 8/48 --
eta - 0.25
gamma - 0
depth - 5
c_weight - 2
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6087962479350415
 Best Acc: 0.23049645390070922
 Avg Loss: 1.6087962479350415
  Avg Acc: 0.23049645390070922

-- Configuration 9/48 --
eta - 0.25
gamma - 0
depth - 8
c_weight - 1
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6093183016629085
 Best Acc: 0.1981382978723404
 Avg Loss: 1.6093183016629085
  Avg Acc: 0.1981382978723404

-- Configuration 10/48 --
eta - 0.25
gamma - 0
depth - 8
c_weight - 1
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6090162506340244
 Best Acc: 0.2225177304964539
 Avg Loss: 1.6090162506340244
  Avg Acc: 0.2225177304964539

-- Configuration 11/48 --
eta - 0.25
gamma - 0
depth - 8
c_weight - 2
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6095075964504946
 Best Acc: 0.22384751773049646
 Avg Loss: 1.6095075964504946
  Avg Acc: 0.22384751773049646

-- Configuration 12/48 --
eta - 0.25
gamma - 0
depth - 8
c_weight - 2
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6091033282643514
 Best Acc: 0.21187943262411346
 Avg Loss: 1.6091033282643514
  Avg Acc: 0.21187943262411346

-- Configuration 13/48 --
eta - 0.25
gamma - 1
depth - 1
c_weight - 1
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6094221198495398
 Best Acc: 0.3280141843971631
 Avg Loss: 1.6094221198495398
  Avg Acc: 0.3280141843971631

-- Configuration 14/48 --
eta - 0.25
gamma - 1
depth - 1
c_weight - 1
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6093820149065754
 Best Acc: 0.16622340425531915
 Avg Loss: 1.6093820149065754
  Avg Acc: 0.16622340425531915

-- Configuration 15/48 --
eta - 0.25
gamma - 1
depth - 1
c_weight - 2
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6094431541067489
 Best Acc: 0.3271276595744681
 Avg Loss: 1.6094431541067489
  Avg Acc: 0.3271276595744681

-- Configuration 16/48 --
eta - 0.25
gamma - 1
depth - 1
c_weight - 2
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6093820149065754
 Best Acc: 0.16622340425531915
 Avg Loss: 1.6093820149065754
  Avg Acc: 0.16622340425531915

-- Configuration 17/48 --
eta - 0.25
gamma - 1
depth - 5
c_weight - 1
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6088551255933783
 Best Acc: 0.21409574468085107
 Avg Loss: 1.6088551255933783
  Avg Acc: 0.21409574468085107

-- Configuration 18/48 --
eta - 0.25
gamma - 1
depth - 5
c_weight - 1
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6090693841060848
 Best Acc: 0.2566489361702128
 Avg Loss: 1.6090693841060848
  Avg Acc: 0.2566489361702128

-- Configuration 19/48 --
eta - 0.25
gamma - 1
depth - 5
c_weight - 2
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.608965904683086
 Best Acc: 0.18927304964539007
 Avg Loss: 1.608965904683086
  Avg Acc: 0.18927304964539007

-- Configuration 20/48 --
eta - 0.25
gamma - 1
depth - 5
c_weight - 2
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6088083780086633
 Best Acc: 0.20124113475177305
 Avg Loss: 1.6088083780086633
  Avg Acc: 0.20124113475177305

-- Configuration 21/48 --
eta - 0.25
gamma - 1
depth - 8
c_weight - 1
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6092704892264191
 Best Acc: 0.1981382978723404
 Avg Loss: 1.6092704892264191
  Avg Acc: 0.1981382978723404

-- Configuration 22/48 --
eta - 0.25
gamma - 1
depth - 8
c_weight - 1
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6085407535235088
 Best Acc: 0.22916666666666666
 Avg Loss: 1.6085407535235088
  Avg Acc: 0.22916666666666666

-- Configuration 23/48 --
eta - 0.25
gamma - 1
depth - 8
c_weight - 2
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6090213988266937
 Best Acc: 0.22562056737588654
 Avg Loss: 1.6090213988266937
  Avg Acc: 0.22562056737588654

-- Configuration 24/48 --
eta - 0.25
gamma - 1
depth - 8
c_weight - 2
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6092073310774269
 Best Acc: 0.2154255319148936
 Avg Loss: 1.6092073310774269
  Avg Acc: 0.2154255319148936

-- Configuration 25/48 --
eta - 0.35
gamma - 0
depth - 1
c_weight - 1
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6094115796558401
 Best Acc: 0.3275709219858156
 Avg Loss: 1.6094115796558401
  Avg Acc: 0.3275709219858156

-- Configuration 26/48 --
eta - 0.35
gamma - 0
depth - 1
c_weight - 1
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6093642186928303
 Best Acc: 0.1600177304964539
 Avg Loss: 1.6093642186928303
  Avg Acc: 0.1600177304964539

-- Configuration 27/48 --
eta - 0.35
gamma - 0
depth - 1
c_weight - 2
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6094851505460468
 Best Acc: 0.3257978723404255
 Avg Loss: 1.6094851505460468
  Avg Acc: 0.3257978723404255

-- Configuration 28/48 --
eta - 0.35
gamma - 0
depth - 1
c_weight - 2
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6093642186928303
 Best Acc: 0.1600177304964539
 Avg Loss: 1.6093642186928303
  Avg Acc: 0.1600177304964539

-- Configuration 29/48 --
eta - 0.35
gamma - 0
depth - 5
c_weight - 1
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6091142736956583
 Best Acc: 0.2052304964539007
 Avg Loss: 1.6091142736956583
  Avg Acc: 0.2052304964539007

-- Configuration 30/48 --
eta - 0.35
gamma - 0
depth - 5
c_weight - 1
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6094801691724054
 Best Acc: 0.1804078014184397
 Avg Loss: 1.6094801691724054
  Avg Acc: 0.1804078014184397

-- Configuration 31/48 --
eta - 0.35
gamma - 0
depth - 5
c_weight - 2
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.609292396311219
 Best Acc: 0.18173758865248227
 Avg Loss: 1.609292396311219
  Avg Acc: 0.18173758865248227

-- Configuration 32/48 --
eta - 0.35
gamma - 0
depth - 5
c_weight - 2
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.609165073128034
 Best Acc: 0.19237588652482268
 Avg Loss: 1.609165073128034
  Avg Acc: 0.19237588652482268

-- Configuration 33/48 --
eta - 0.35
gamma - 0
depth - 8
c_weight - 1
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6084661676105878
 Best Acc: 0.19946808510638298
 Avg Loss: 1.6084661676105878
  Avg Acc: 0.19946808510638298

-- Configuration 34/48 --
eta - 0.35
gamma - 0
depth - 8
c_weight - 1
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6094945158201752
 Best Acc: 0.21187943262411346
 Avg Loss: 1.6094945158201752
  Avg Acc: 0.21187943262411346

-- Configuration 35/48 --
eta - 0.35
gamma - 0
depth - 8
c_weight - 2
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6106742389552982
 Best Acc: 0.21631205673758866
 Avg Loss: 1.6106742389552982
  Avg Acc: 0.21631205673758866

-- Configuration 36/48 --
eta - 0.35
gamma - 0
depth - 8
c_weight - 2
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6092663437973522
 Best Acc: 0.2220744680851064
 Avg Loss: 1.6092663437973522
  Avg Acc: 0.2220744680851064

-- Configuration 37/48 --
eta - 0.35
gamma - 1
depth - 1
c_weight - 1
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6094115796558401
 Best Acc: 0.3275709219858156
 Avg Loss: 1.6094115796558401
  Avg Acc: 0.3275709219858156

-- Configuration 38/48 --
eta - 0.35
gamma - 1
depth - 1
c_weight - 1
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6093642186928303
 Best Acc: 0.1600177304964539
 Avg Loss: 1.6093642186928303
  Avg Acc: 0.1600177304964539

-- Configuration 39/48 --
eta - 0.35
gamma - 1
depth - 1
c_weight - 2
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6094851505460468
 Best Acc: 0.3257978723404255
 Avg Loss: 1.6094851505460468
  Avg Acc: 0.3257978723404255

-- Configuration 40/48 --
eta - 0.35
gamma - 1
depth - 1
c_weight - 2
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6093642186928303
 Best Acc: 0.1600177304964539
 Avg Loss: 1.6093642186928303
  Avg Acc: 0.1600177304964539

-- Configuration 41/48 --
eta - 0.35
gamma - 1
depth - 5
c_weight - 1
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6090609959148345
 Best Acc: 0.18173758865248227
 Avg Loss: 1.6090609959148345
  Avg Acc: 0.18173758865248227

-- Configuration 42/48 --
eta - 0.35
gamma - 1
depth - 5
c_weight - 1
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.609880693943788
 Best Acc: 0.18617021276595744
 Avg Loss: 1.609880693943788
  Avg Acc: 0.18617021276595744

-- Configuration 43/48 --
eta - 0.35
gamma - 1
depth - 5
c_weight - 2
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6092901097755905
 Best Acc: 0.18173758865248227
 Avg Loss: 1.6092901097755905
  Avg Acc: 0.18173758865248227

-- Configuration 44/48 --
eta - 0.35
gamma - 1
depth - 5
c_weight - 2
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6089661504994048
 Best Acc: 0.22872340425531915
 Avg Loss: 1.6089661504994048
  Avg Acc: 0.22872340425531915

-- Configuration 45/48 --
eta - 0.35
gamma - 1
depth - 8
c_weight - 1
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.607601099033305
 Best Acc: 0.22163120567375885
 Avg Loss: 1.607601099033305
  Avg Acc: 0.22163120567375885

-- Configuration 46/48 --
eta - 0.35
gamma - 1
depth - 8
c_weight - 1
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6087468426595344
 Best Acc: 0.21852836879432624
 Avg Loss: 1.6087468426595344
  Avg Acc: 0.21852836879432624

-- Configuration 47/48 --
eta - 0.35
gamma - 1
depth - 8
c_weight - 2
reg_lambda - 0.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.610430544572519
 Best Acc: 0.22562056737588654
 Avg Loss: 1.610430544572519
  Avg Acc: 0.22562056737588654

-- Configuration 48/48 --
eta - 0.35
gamma - 1
depth - 8
c_weight - 2
reg_lambda - 1.5
Repeat 1/1
Loading features
Fitting model
Creating DMatrix
Training
Saving model
Best Loss: 1.6092344908743885
 Best Acc: 0.21941489361702127
 Avg Loss: 1.6092344908743885
  Avg Acc: 0.21941489361702127

--- Final Results ---
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| Pos | Loss  |  Acc  |                                 Params                                  |              Filename               |
+=====+=======+=======+=========================================================================+=====================================+
|  1  | 1.608 | 0.222 | {'eta': 0.35, 'gamma': 1, 'depth': 8, 'c_weight': 1, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-19_00:09:30.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
|  2  | 1.608 | 0.199 | {'eta': 0.35, 'gamma': 0, 'depth': 8, 'c_weight': 1, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_23:25:51.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
|  3  | 1.609 | 0.229 | {'eta': 0.25, 'gamma': 1, 'depth': 8, 'c_weight': 1, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_22:48:14.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
|  4  | 1.609 | 0.219 | {'eta': 0.35, 'gamma': 1, 'depth': 8, 'c_weight': 1, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-19_00:15:23.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
|  5  | 1.609 | 0.230 | {'eta': 0.25, 'gamma': 0, 'depth': 5, 'c_weight': 2, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_21:52:54.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
|  6  | 1.609 | 0.201 | {'eta': 0.25, 'gamma': 1, 'depth': 5, 'c_weight': 2, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_22:36:29.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
|  7  | 1.609 | 0.214 | {'eta': 0.25, 'gamma': 1, 'depth': 5, 'c_weight': 1, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_22:25:02.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
|  8  | 1.609 | 0.264 | {'eta': 0.25, 'gamma': 0, 'depth': 5, 'c_weight': 1, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_21:45:13.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
|  9  | 1.609 | 0.189 | {'eta': 0.25, 'gamma': 1, 'depth': 5, 'c_weight': 2, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_22:32:39.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 10  | 1.609 | 0.229 | {'eta': 0.35, 'gamma': 1, 'depth': 5, 'c_weight': 2, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-19_00:03:40.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 11  | 1.609 | 0.189 | {'eta': 0.25, 'gamma': 0, 'depth': 5, 'c_weight': 2, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_21:49:06.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 12  | 1.609 | 0.201 | {'eta': 0.25, 'gamma': 0, 'depth': 5, 'c_weight': 1, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_21:41:25.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 13  | 1.609 | 0.223 | {'eta': 0.25, 'gamma': 0, 'depth': 8, 'c_weight': 1, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_22:04:38.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 14  | 1.609 | 0.226 | {'eta': 0.25, 'gamma': 1, 'depth': 8, 'c_weight': 2, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_22:54:05.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 15  | 1.609 | 0.182 | {'eta': 0.35, 'gamma': 1, 'depth': 5, 'c_weight': 1, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_23:52:08.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 16  | 1.609 | 0.257 | {'eta': 0.25, 'gamma': 1, 'depth': 5, 'c_weight': 1, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_22:28:50.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 17  | 1.609 | 0.212 | {'eta': 0.25, 'gamma': 0, 'depth': 8, 'c_weight': 2, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_22:16:24.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 18  | 1.609 | 0.205 | {'eta': 0.35, 'gamma': 0, 'depth': 5, 'c_weight': 1, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_23:08:34.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 19  | 1.609 | 0.192 | {'eta': 0.35, 'gamma': 0, 'depth': 5, 'c_weight': 2, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_23:20:00.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 20  | 1.609 | 0.215 | {'eta': 0.25, 'gamma': 1, 'depth': 8, 'c_weight': 2, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_22:59:57.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 21  | 1.609 | 0.219 | {'eta': 0.35, 'gamma': 1, 'depth': 8, 'c_weight': 2, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-19_00:27:07.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 22  | 1.609 | 0.222 | {'eta': 0.35, 'gamma': 0, 'depth': 8, 'c_weight': 2, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_23:43:32.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 23  | 1.609 | 0.198 | {'eta': 0.25, 'gamma': 1, 'depth': 8, 'c_weight': 1, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_22:42:19.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 24  | 1.609 | 0.182 | {'eta': 0.35, 'gamma': 1, 'depth': 5, 'c_weight': 2, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_23:59:49.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 25  | 1.609 | 0.182 | {'eta': 0.35, 'gamma': 0, 'depth': 5, 'c_weight': 2, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_23:16:11.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 26  | 1.609 | 0.198 | {'eta': 0.25, 'gamma': 0, 'depth': 8, 'c_weight': 1, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_21:58:45.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 27  | 1.609 | 0.160 | {'eta': 0.35, 'gamma': 0, 'depth': 1, 'c_weight': 1, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_23:02:21.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 28  | 1.609 | 0.160 | {'eta': 0.35, 'gamma': 0, 'depth': 1, 'c_weight': 2, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_23:04:45.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 29  | 1.609 | 0.160 | {'eta': 0.35, 'gamma': 1, 'depth': 1, 'c_weight': 1, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_23:45:56.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 30  | 1.609 | 0.160 | {'eta': 0.35, 'gamma': 1, 'depth': 1, 'c_weight': 2, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_23:48:20.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 31  | 1.609 | 0.166 | {'eta': 0.25, 'gamma': 0, 'depth': 1, 'c_weight': 1, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_21:35:11.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 32  | 1.609 | 0.166 | {'eta': 0.25, 'gamma': 0, 'depth': 1, 'c_weight': 2, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_21:37:36.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 33  | 1.609 | 0.166 | {'eta': 0.25, 'gamma': 1, 'depth': 1, 'c_weight': 1, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_22:18:49.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 34  | 1.609 | 0.166 | {'eta': 0.25, 'gamma': 1, 'depth': 1, 'c_weight': 2, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_22:21:13.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 35  | 1.609 | 0.328 | {'eta': 0.35, 'gamma': 0, 'depth': 1, 'c_weight': 1, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_23:01:09.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 36  | 1.609 | 0.328 | {'eta': 0.35, 'gamma': 1, 'depth': 1, 'c_weight': 1, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_23:44:44.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 37  | 1.609 | 0.328 | {'eta': 0.25, 'gamma': 0, 'depth': 1, 'c_weight': 1, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_21:33:58.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 38  | 1.609 | 0.328 | {'eta': 0.25, 'gamma': 1, 'depth': 1, 'c_weight': 1, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_22:17:36.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 39  | 1.609 | 0.327 | {'eta': 0.25, 'gamma': 0, 'depth': 1, 'c_weight': 2, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_21:36:24.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 40  | 1.609 | 0.327 | {'eta': 0.25, 'gamma': 1, 'depth': 1, 'c_weight': 2, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_22:20:02.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 41  | 1.609 | 0.180 | {'eta': 0.35, 'gamma': 0, 'depth': 5, 'c_weight': 1, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_23:12:23.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 42  | 1.609 | 0.326 | {'eta': 0.35, 'gamma': 0, 'depth': 1, 'c_weight': 2, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_23:03:33.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 43  | 1.609 | 0.326 | {'eta': 0.35, 'gamma': 1, 'depth': 1, 'c_weight': 2, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_23:47:08.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 44  | 1.609 | 0.212 | {'eta': 0.35, 'gamma': 0, 'depth': 8, 'c_weight': 1, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_23:31:43.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 45  | 1.610 | 0.224 | {'eta': 0.25, 'gamma': 0, 'depth': 8, 'c_weight': 2, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_22:10:29.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 46  | 1.610 | 0.186 | {'eta': 0.35, 'gamma': 1, 'depth': 5, 'c_weight': 1, 'reg_lambda': 1.5} | alexnet_xgb_2019-11-18_23:56:00.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 47  | 1.610 | 0.226 | {'eta': 0.35, 'gamma': 1, 'depth': 8, 'c_weight': 2, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-19_00:21:14.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
| 48  | 1.611 | 0.216 | {'eta': 0.35, 'gamma': 0, 'depth': 8, 'c_weight': 2, 'reg_lambda': 0.5} | alexnet_xgb_2019-11-18_23:37:40.pth |
+-----+-------+-------+-------------------------------------------------------------------------+-------------------------------------+
